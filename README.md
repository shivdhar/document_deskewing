# Document Deskewing

## Task

Given an arbitrary image containing text, rotate it such that the text is horizontal and the right side up.

## Approach

### Conventional Approaches

- One way to deskew documents is to use the Hough transform.
The process is:
    - read an RGB image
    - convert to grayscale
    - apply Canny/Sobel filters for edge detection
    - apply the Hough transform to detect lines
    - given the lines, calculate the orientation of the longest lines.

- The FFT algorithm can be also be used. We apply it in [00_fft.ipynb](00_fft.ipynb). Here, we find the orientation of a center line generated by the transform ,and rotate it accordingly.

These geometry-based techniques suffer from the flaw that while they understand lines, they do not understand text and its orientation. Hence, a fully flipped image remains so, because its lines are not skewed.

To solve this, we try to look at techniques which can recognize *text* instead of lines and detect their skewness accordingly.

We looked at PaddleOCR which is near the top of the leaderboard for scene text detection. However, it only has a CLI-based interface which draws the bounding boxes in the image directly. More crucially, it failed to detect text in flipped and rotated documents.

This was a good opportunity to explore Google Cloud's AI Vision APIs. We tried it and it gave remarkably accurate results, even for documents which had been completely flipped. Most importantly, the vertices it returns for bounding boxes were ordered, starting from the upper left corner of a text segment, ensuring that no matter what the orientation of the text, the correct angle could be calculated.

- We try this approach in [04_gcp_vision.ipynb](04_gcp_vision.ipynb) and it gave remarkable results. Please see the results at the end of the notebook. Note: To run the notebook, an API key needs to generated and placed at `gcp_credentials.json`.

### Approach

- The basic idea is to obtain the orientation of text characters/words/sentences/blocks/paragraghs
- Compare with the previous approaches of getting the orientation of the "image" as opposed to the text within it.
- To do this, we need the bounding boxes of the text characters. This can be provided by GCP (as here) or with some other component, probably a neural network.

## References and Further Reading

- https://github.com/zacharywhitley/awesome-ocr
- https://becominghuman.ai/how-to-automatically-deskew-straighten-a-text-image-using-opencv-a0c30aed83df
- https://medium.com/@9sphere/machine-vision-recipes-deskewing-document-images-e178278- https://www.pyimagesearch.com/2017/02/20/text-skew-correction-opencv-python/94c34

